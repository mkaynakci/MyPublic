Summary of user research
This  is a report on initial investigation into residents' feelings, fears and hopes around the use of artificial intelligence in public sector services as well as their understanding of AI and key aspects of Surrey County Council AI strategy.
As part of resident engagement that took place in July 2023 we conducted short-burst in person interviews with 21 residents. Outcomes of the engagement are presented in this document.
Following the engagement, we believe the below objectives and questions should be explored before taking further steps in implementation of AI tool across SCC services so that we ensure we take a human centric approach and no one is left behind. A research plan to support a future project has been drafted and should be reviewed and finalised once a future research project is formalised. 

The answer to the questions below
What do you know about Artificial Intelligence? 

Where did you hear about it?

Do you think you already use AI in your day to day life?



Despite frequently expressing lack of confidence when it comes to discussing the subject of AI (especially if they are not confident with technology in general) residents we spoke to had a high level of awareness of artificial intelligence. 
What AI powered technology means is hard to envision and some residents had a clear scientific understanding of AI, some saw it as a separate device like laptop or something you can opt out of, others confused it with artificial general intelligence. 
Media outlets (TV, news, social media) and popular culture (films and tv shows) are the main sources of information about what artificial intelligence is, how it’s used and what it’s capacity is.
Media messaging often links to technology used for scams, failed experiments, issues that concern tech companies and dystopian futures where humans are oppressed,  where jobs are at risk and “the whole world is about to change”.  
Residents recognise flaws in media coverage and believe that education and access to reliable information is the key.  Some have complained about inaccessibility of the language used in conversations about AI and lack of access to easy to understand information about it.
Some residents believe AI is “overinflated” and “still in it’s infancy” and are cautious about the idea of it being implemented when “we don’t know enough about it” and expressed concerns over "exposing our children to it"
Most participants thought AI is used in private sector products and services Amazon or online shopping frequently used as example, residents also mentioned self check out tills in supermarkets, ChatGPT, advertising, film production and emails (AI generated text content).
Older residents were more afraid of the new, unfamiliar technology and the impact it will have on the world around them.


How does it make you feel when you’re hearing or thinking about AI?
Negative 
Residents fear and are concerned about:
new technology mixed with lack of access to easy to understand information and education
impact of using AI (especially younger generations and those who are digitally excluded)
lack of satisfaction while interacting with machines
being exposed to fraud and scams (impersonation), loss of privacy
Systems becoming dependent on AI (even if it doesn’t work well or is overinflated)
lack of flexibility of the system inability to interact with a person rather than an AI tool
increase of inequality
community impact, isolation 
loss of jobs

Adjectives used most often by residents to describe AI: scary, frightening, worrying

Bias 
There were mixed reactions around bias and AI. Some believed AI will be less biased than the employees making decisions, some believed it will exaggerate bias humans have.
Some believed AI to be vulnerable to people manipulating AI ("people can cheat AI") for selfish gains or bad actors using it for intentional harm to a person or groups of people.  

Neutral/
Hesitant to pick a side
Some of the residents expressed neutral opinions focused on the themes of not knowing enough and a sense of mystery around AI. 
A few of the residents saw a balance between positive and negative outcomes of AI implementations. They also raised the following issues:
risk of unknown problems with AI (ie. new crimes)
consequences of using AI in services (bias, responsibility, visibility)

Hopes
Some of the residents had positive attitude towards AI because they believed it can reduce workload, give faster access to services(eg: parking, transport), has advances in medical research, can help with staffing problems in public sector

AI in public sector
Following a conversation about what is AI, how it might be used in private sector and how our residents feel about it, we asked how would they feel about public sector organisations, like the council use similar tools.
Residents have doubts about public organisations ability and competency to understand and implement solutions that rely on artificial intelligence. Aside from concerns about invasion of privacy, security, bias, decision accuracy some residents were also voicing concerns about ulterior motives behind implementation (selling data, pushing people away).

Residents were also concerned about impact this would have on their relationship with the council. In post-covid world they already feel like services and officers are less resident friendly and that digital solutions are forced on them. 

Using AI in different public sector services
Users tried to distinguish between what AI should and should not be left to do. Things that can “cause harm”, "something that can cost someone's life", mental health, something that needs flexibility, persistence to fight till you get help, empathy are tasks they believed should not be left to AI. 

Services that could benefit from using AI tools:
Cancer detection
Medical research
Parking
Transport
Report and repairs

Services that shouldn’t be using  AI tools:
Decision making (without human input) that causes harm
Services that are nuanced and require flexibility or dealing with unusual circumstances/factors. "something that is not in the forms can help someone"
Policing
Criminal investigations
Sensitive services, services that require your private data
Mental health services
Phone lines
Hospitals
“Anything related to politics”

Most residents believe that AI tools can be used successfully if people supervise the process and have a final sign off on tasks, because humans have empathy, ability to understand complex situations and be flexible and show appropriate emotions.

Regulations are required but residents have no confidence in regulators being ahead of technology. Some people expressed their lack of confidence in regulations being ahead of technology. 1 user said Council using AI will increase her trust in AI. 


Recommendations
Further in-depth research into:
Residents and staff feelings, perceptions and needs in relation to AI strategy and digital services in general
What are the limitations of the technology? (i.e.. training and education related challenges and explainability of decisions)
How do those limitations interplay with user trust and behaviour?
What does implementation of AI tools mean to users with accessibility needs?
What are the examples and results of implementing AI technology in public services? And what can we learn from it?
