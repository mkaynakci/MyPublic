Introduction 

It's important that the Web Team keep track with an ever-changing online landscape. That includes the tools we all use to create, access and read content. 

 

The past couple of years has seen us focus heavily on accessibility. Surrey staff now create documents that are more accessible thanks to our Accessibility Machine. This helps the thousands of residents that have impairments affecting their access to web content. 

 

But improving the quality of content creation and readability is also important. We have residents of all different reading levels, so the content we publish needs to be clear, simple, and quick to read – so they can do more online. 

 

That's where the next big thing comes in: Artificial Intelligence (AI) 

 

Students are using it to write their essays, and in some Surrey schools, teachers say they've used it to help with end-of-year report writing. It's getting harder to spot the difference, too. 

 

What we want to know is: if it can write an essay that's indistinguishable from an organically-authored one, can it do the same for public sector information? And can it make that content clearer, simpler and quicker to read, too? 

 

First test: reduce reading age 

We first want to check if the current AI solutions can help reduce the ‘reading age’ of service content published on the website. 

 

‘Reading age’ is a useful metric of how easy a piece of content is to read. It's measured by processing the content and checking things like sentence length and characters per word. A score is then produced, approximated to the expected reading level of an age group. 

 

While it's not foolproof – for one, it doesn't measure the actual quality, sense or logic of the content – it's a handy way to automate content quality checks (read more about readability). 

 

GOV.UK sets its own target reading age of 9 years old. While we’re working hard to deliver a much-improved ‘writing for the web’ training package, this target is hard to achieve even for the most seasoned copywriter.  

 

To see if AI can help, we'll feed chunks of content from 5 of our most-read webpages and see what it can do. 

 

Second test: generate meta descriptions 

We also want to see if AI can help create meta descriptions for these same pages.  

 

Meta descriptions are the snippets of text you see below each result in search engines like Google. They’re a tiny sales pitch to residents, telling them if they should click on the page, what it contains, and what it can help them do. 

 

Pages without one are more likely to struggle to get picked in the sea of search results. 

 

Our web standards ask that page authors write a meta description for every page they publish. But they can be tricky to write as a sales pitch for the page – and some are low quality, too long, too short, or repeat many of the keywords in the page title. This all affects search engine optimisation (SEO). 

 

It's a time-consuming process, so we want to see if AI can help.  

 

We’ll be feeding 5 of our most-read pages into it, asking for meta descriptions (ideally Google's recommended length: between 110 and 160 characters), and seeing how they compare to the service authored versions. 

 

Why we're not generating content from scratch 

The relative youth and inherent risks of the technology mean we’re not looking for content creation from scratch. Instead, we're looking for readability improvements in post – that’s after the content has been written accurately by our service authors. 

 

This limits the risk of what are termed ‘hallucinations’ by AI architects – or, more appropriately, stuff that the AI has made up to look smarter than it is. AI still cannot tell if what it produces is correct or not, and that’s a big problem for any serious, original content creation. 

 

And the nature of local government content makes it even less viable: the information is often locality-specific, completely new, or (by necessity) different from council to council. So there's far fewer relevant, trustworthy sources for an AI to crawl and use in its response. 

 

This is in contrast to an essay question like ‘What were the causes of World War 1?'. Countless articles, essays, books, and student theses have covered this topic. Which means the AI has plenty of sources to amalgamate into a convincing piece of content. 

 

And this doesn't even include the potential ethical dilemmas of such a use-case (more on that below). So while we may return to this topic in future, for now, we’re looking strictly at its viability for improving readability of pre-prepared content. 

 

Risks 

  

 

Inaccuracy of output requires manual checking 

Can remove content from final output for no discernable reason 

No control over source of AI technology, so cannot be fully relied on for consistency 

No control over new updates, security, or origin of content 

Manufactured responses 

Inadvertently contributing towards the improvement of AI (subjective risk) 

Ethical issues detailed here 

For more on the risks, read part 1.2 ‘Managing AI risks’ of the government's policy paper ‘A pro-innovation approach to AI regulation’ (GOV.UK). This includes its 5 principles to guide and inform the responsible development and use of AI: 

  

 

Safety, security and robustness 

Appropriate transparency and explainability 

Fairness 

Accountability and governance 

Contestability and redress 

 

…like, for instance, when you ask a bot for a definition of something that doesn’t exist and it, rather convincingly, gives you one, complete with made-up footnotes. 

  

 

“No one in the field has yet solved the hallucination problems,” Sundar Pichai, the CEO of Google and Alphabet, told an interviewer recently. 

 

'AI machines aren’t ‘hallucinating’. But their makers are', Naomi Kline, Guardian, 8 May 2023 

 

Ethics 

There are also ethical concerns to using these technologies. 

 

The source of the AI’s ‘intelligence' is one. All of these tools have been (and continue to be) trained on almost everything ever written. And in the vast majority of cases, without the permission of the original author or publisher. 

 

Numerous articles have also been written about AI’s impact on the environment through the energy it consumes, the existential risk to our future when its intelligence supersedes our own, and the potential job losses it could cause. 

 

On the flip side, articles have been written about how AI could solve many of those same concerns: inventing solutions to the climate crisis, drastically improving the speed of medicine development, and freeing us up to enjoy more leisure time. 

 

The former are rooted in evidence, past and present. Much of the latter are still just predictions – often from the originators of these new technologies. 

 

So, while the practical outputs of this test will be outdated in a matter of months or even days, the ethical concerns are likely to remain. The technology is too widespread now for our legal systems to satisfactorily rectify things like the intellectual property violations, These will always remain at the foundation of these tools. 

 

Whichever side you fall on (or a mix of the two), serious thought is needed before we start to use these technologies in the public sector. But as we’re seeing in other industries, this may all be pushed to the back of the mind in a race to keep up with the competition, follow industry trends or, most likely, keep costs down. 

 

For all we know, some colleagues here may already have made their minds up and started using these tools. It could be an email, a presentation, or new webpage – if it seems a bit generic, then who knows? 

 

Early conclusions 

On page content readability 

Looking at the readability metric in isolation, Google Bard shows the strongest abilities to help, rather than hinder, our work. 

 

But we'll need to take a closer look at the before/after of the content before making any decision on a preferred tool. Particularly to check for any of those ‘hallucinations’ that AI has a tendency for. 

 

That's the next stage for us, as well as more detailed prompts and looking beyond the readability metric. But for now, Google Bard is the strongest at reducing the reading age with a single prompt. 

 

Extra benefits for search optimisation and quick reading 

One of the extra benefits of Google Bard appears to be its ability to ‘chunk up' the content in a more web-friendly way. That means shortening sentences and paragraphs, simplifying terminology, and adding relevant subheadings to aid quick reading. These techniques make the content quicker to read, and to skim and scan through – critical to short attention spans. 

 

It's probably because it's a Google tool that it's strongest in these web-friendly techniques. It will know better than anyone what online readers are looking for in good content, as that's what it needs to serve users of its search engine. 

 

A human content writer is still preferred 

The outputs still suggest that a well-skilled (human!) content writer is still the better option. They know their audience, the intricacies of the content, its purpose, and are also better at writing with a natural flow.  

 

Even if the skill level of the content writer isn't that high, they're still critical to the process before (knowing what the content needs to contain) and after (checking that the content covers everything well). 

 

In our tests, this is best-demonstrated in the ‘Renewing library items’ page. No tool was able to better the readability of the existing page, with most actually making it a bit worse. 

 

The risks and alternatives 

The outputs also demonstrate the risks of using these tools on content like ‘Adult social care assessments and eligibility’.  

 

Google Bard used Coventry Council's website as a reference, which suggests it may subtly alter some terminology to match existing copy, even if it doesn't apply to Surrey's specific needs. Again, we're not in control of what these tools use for their ‘intelligence’, so we have to be cautious. 

 

It's also worth noting that it's still relatively quick to improve readability in-situ using a more manual, semi-automatic tool like Hemingway App. 

 

While pasting into an AI tool is quick, and the process takes a matter of seconds, having the edits taken out of your hands and then requiring a close read-through may mean there isn't as much in it as we think. 

 

With a less fully-automated tool, the benefits are a closer read and genuine upskilling. So for now, this is still the method we recommend. 

 

On meta description generation 

The results of the meta description generation are much closer to the real thing. And this suggests a real potential for taking a fairly frustrating task off our web authors' workload. 

 

None of the results were perfect - extra prompts are needed to refine some web standards issues, like replacing the passive 'Surrey County Council’ with the active ‘We’. 

 

But generally the results were ‘good enough’ to genuinely consider using AI for this purpose. While a good page author will still write a better page description than what's on show here, if AI can do this small task almost as well, is their time better spent on the main page content instead? 

 

As to which is the strongest performer, again it's Google Bard. Chat GPT has an obvious formula, more suited to ecommerce, while the others are weaker still, not fully understanding the requirements of a good meta description. 

 

Even with Bard there are issues: It often exceeds its own recommended character count for descriptions (110 to 160 characters). And its accompanying text always claims a 155 character description, regardless of length. We can expect this to be fixed in future, but it may require additional prompts to refine. 

 

Lastly, it's worth bearing in mind that the success of Google Bard could mean Google makes manually-written meta descriptions obsolete anyway. Even now, it often decides to use its own versions, so the decision could be taken out of our hands. 

 

In the modern world, too much of our professional lives are taken up by monotonous tasks – inputting data, filling out paperwork, scanning through documents for one piece of information and so on. 

 

Ministerial Foreword, ‘A pro-innovation approach to AI regulation’, GOV.UK 

 

Next steps 

We're going to take the meta description generation use-case seriously. It's a potential time-saver, and with the closed loop of the request ('read only our page and summarise it') we potentially negate some, but not all, of the ethical concerns we've raised. 

 

As for content readability, page authors are welcome to give it a try and see how they get on (pending more general guidance).  

 

For us, we'll be carrying out further, more in-depth tests on some content, looking in greater detail at syntax, logic, web standards, accessibility, consistency, and using extra prompts. We'll also discuss the ethical concerns in greater detail. 

 

Finally, we need to consider how AI could fit into a hypothetical page author workflow:  

  

Should it be used to create a first draft using prompts, or to refine an already-written piece of content? 

What guidance would be needed for its use (prompt examples, notes of caution)? 

How would we make sure we're always using the right tool? 

How would the post-process read-through work, and how long would it take? 

How much time would it actually save? 

Most importantly, how do we – and this is the wider council ‘we’ now – make sure the use of these tools is safe and reliable, and still puts our residents first? 
